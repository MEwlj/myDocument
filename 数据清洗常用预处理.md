

# 数据清洗常用预处理

## 1.读取数据

### 1.1 pd.read_csv()

1. pd.read_csv(filepath_or_buffer,header,names)

- header=0,第1行数据做为列标题(默认设置)
- header=None,没有列标题,系统自动加上数字序列
- names参数:自定义列标题，代替header参数指定的列标题。首先将header=0，第1行做为列标题，再设置names参数,指定新的列标题。

2. read_csv中还含有parse_dates和index_col等重要参数参数

![Image](C:\Users\acer-pc\Desktop\办公\自己写的资料\picture\数据清洗常见预处理\Image.png)



### 1.2 read_excel(filepath_or_buffer,sheet_name='')

1. 因为excel有多个sheet，故有一个sheet_name来指定具体选择哪一个sheet



## 2. 处理数据

### 2.1 df.head(n)和df.tail()

1. head()函数:参数为空时,默认读取二维数据表中的前5行数据,head(n)读取前n行数据。
2. tail()同理。



### 2.2 df转化为numpy数组

1. np.array(df)转化为numpy数组

2. df.values

3. df.as_matrix()

   

   ps: np.asarray()用于把列表转化为数组



### 2.3 pd.isnull()

1. 能够返回一个布尔型的二维表格

#### 2.3.1pd.isnull().T.any()

返回一个Series的布尔类型，这是提取空值所在的行。.T是转置，.any()表示逻辑或。因为.any()是对列提取逻辑或，因此要想取原来的有空值的行索引，必须要先转置。

#### 2.3 pd.isnull().T.sum()

查看该行有多少个空值，返回值也是一个Series类型。



### 2.4 df[布尔型索引].index.tolist()

通过布尔型索引查找到需要的行，用.tolist()方法将其转换成列表。返回值是一个列表。



### 2.5 df.rename(columns={"old_name":"new_name"},inplace=True)

给df表格的具体某一列重命名。重命名的方法有3种

1. 部分重命名

```
dataframe.rename(columns = {"old_name": "new_name"})  # 此时需要重新给原变量赋值
dataframe.rename(columns = {"old1": "new1", "old2":"new2"},  inplace=True)
```

2. 全部重命名 columns = new_columns

```
new_col = ['new1', 'new2',... , 'newn']
dataframe.columns = new_col
```

3. 读取文件重命名

```
pd.read_csv('data', names = new_col, header=0)
```



### 2.6 np.random.randint()

```
numpy.random.randint(low, high=None, size=None, dtype=None)

```

1. 函数的作用是，返回一个随机整型数，范围从低（包括）到高（不包括），即[low, high)。
   如果没有写参数high的值，则返回[0,low)的值。

2. 参数：

   - low:int	生成的数值最低要大于等于low。

   （hign = None时，生成的数值要在[0, low)区间内）

   - high:int(可选)	如果使用这个值，则生成的数值在[low, high)区间。

   - size: int or tuple of ints(可选)

     输出随机数的尺寸，比如size = (m * n* k)则输出同规模即m * n* k个随机数。默认是None的，仅仅返回满足要求的单一随机数。

   - dtype: dtype(可选)：

     想要输出的格式。如`int64`、`int`等等

3. 输出一个随机数或者随机数数组，由size决定。



### 2.7 np.random.choice()

```
    def choice(self, a, size=None, replace=True, p=None): # real signature unknown; restored from __doc__
        """
        choice(a, size=None, replace=True, p=None)
        
                Generates a random sample from a given 1-D array
        
                .. versionadded:: 1.7.0
        
                .. note::
                    New code should use the ``choice`` method of a ``default_rng()``
                    instance instead; please see the :ref:`random-quick-start`.
        
                Parameters
                ----------
                a : 1-D array-like or int
                    If an ndarray, a random sample is generated from its elements.
                    If an int, the random sample is generated as if a were np.arange(a)
                size : int or tuple of ints, optional
                    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
                    ``m * n * k`` samples are drawn.  Default is None, in which case a
                    single value is returned.
                replace : boolean, optional
                    Whether the sample is with or without replacement
                p : 1-D array-like, optional
                    The probabilities associated with each entry in a.
                    If not given the sample assumes a uniform distribution over all
                    entries in a.
        
                Returns
                -------
                samples : single item or ndarray
                    The generated random samples
```

a可以是一个int类型，表示np.arange(a)，replace=True表示有放回抽样，p=None时表示均匀分布，也可以用一个列表来指定分布。

**默认为有放回的抽样 (可以重复)**

- np.random.choice(5, 3)
  - 和np.random.randint(0,5,3)意思相同，表示从[0,5)之间随机以等概率选取3个数
- np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])
  - 表示分别以p=[0.1, 0, 0.3, 0.6, 0]的概率从[0,1,2,3,4]这四个数中选取3个数

**以下为无放回的抽样 （不会出现重复的元素）**

- np.random.choice(a=5, size=3, replace=False, p=None)
- np.random.choice(a=5, size=3, replace=False, p=[0.2, 0.1, 0.3, 0.4, 0.0])

**此方法也可以对列表List类型元素使用**

- aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']
- np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])

参考自[博客](https://www.cnblogs.com/cloud-ken/p/9931273.html)



### 2.8 np.min()和np.max()和np.argmin()

```
import numpy as np  
a = np.array([[1,5,3],[4,2,6]])  
print(a.min()) #无参，所有中的最小值  
print(a.min(0)) # axis=0; 每列的最小值  
print(a.min(1)) # axis=1；每行的最小值  

```

a.min()的结果是：1

a.min(0)的结果是：[1 2 3]

a.min(1)的结果是：[1 2]

a.min(0)求的是某一个维度上的最小值。

np.argmin()参考[博客](https://blog.csdn.net/weixin_41770169/article/details/80714461?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control)



### 2.9 df.corr()相关性分析

```
DataFrame.corr(method='pearson', min_periods=1)
```

参数说明：

- method：可选值为{‘pearson’, ‘kendall’, ‘spearman’}

- pearson：Pearson相关系数来衡量两个数据集合是否在一条线上面，即针对线性数据的相关系数计算，针对非线性数据便会有误差。

- kendall：用于反映分类变量相关性的指标，即针对无序序列的相关系数，非正太分布的数据

- spearman：非线性的，非正太分析的数据的相关系数

- min_periods：样本最少的数据量

- 返回值：各类型之间的相关系数DataFrame表格。

min_periods一般不管。内容参考自[知乎](https://zhuanlan.zhihu.com/p/83523768)



### 2.10 df.dropna()

```
DataFrme.dropna(axis=0,how=’any’,thresh=None,subset=None,inplace=False)
```

**参数**：

1. axis: 默认axis=0。0为按行删除,1为按列删除
2. how: 默认 ‘any’。 ‘any’指带缺失值的所有行/列;'all’指清除一整行/列都是缺失值的行/列
3. thresh: int,保留含有int个非nan值的行
4. subset: 删除特定列中包含缺失值的行或列
5. inplace: 默认False，即筛选后的数据存为副本,True表示直接在原数据上更

代码示例

```
import numpy as np
import pandas as pd
df = pd.DataFrame(np.arange(24).reshape(4,6), index=[‘a’, ‘c’, ‘e’, ‘f’])
df.iloc[0,[1,2,5]]=np.nan
df.iloc[2,[1,4]]=np.nan
print(df)
```

![img](https://img-blog.csdnimg.cn/20200606023948597.png)

然后再

```
df=df.dropna()#删除所有包含NaN的行，相当于参数全部默认
#df=df.dropna(axis=0,how=‘any’,thresh=None,subset=None,inplace=False)
print(df)
```

结果为

![img](https://img-blog.csdnimg.cn/20200606024027913.png)

内容参考自[csdn](https://blog.csdn.net/bamboo_128/article/details/106585634)和[csdn](https://blog.csdn.net/weixin_40283816/article/details/84304055)



### 2.11 删除列表中某个元素

1. pop：删除单个或多个元素，按位删除(根据索引删除)

```
>>> str=[0,1,2,3,4,5,6]
>>> str.pop(1) #pop删除时会返回被删除的元素
>>> str
```

[0, 2, 3, 4, 5, 6]

```
>>> str2=['abc','bcd','dce']
>>> str2.pop(2)
```

'dce'
\>>> str2
['abc', 'bcd']

2. remove： 删除单个元素，删除首个符合条件的元素，按值删除

```
>>> str=[1,2,3,4,5,2,6]
>>> str.remove(2)
>>> str
```

[1, 3, 4, 5, 2, 6]

内容选自[博客](https://www.cnblogs.com/xiaodai0/p/10564956.html)



### 2.12 lambda函数的用法

一些简单的函数可以不用给他特地def一个函数，而是直接用lambda来建立，并且可以与df.apply连用

比如

```
def sum(x,y):
      return x+y
```

就可以通过lambda实现

```
p = lambda x,y:x+y
print(p(4,6))
```

参考自[博客园](https://www.cnblogs.com/kaishirenshi/p/8611358.html)



### 2.13 删除dataframe某行或者某列

采用df.drop()

1. 删除列

![img](https://img2018.cnblogs.com/blog/1023513/201810/1023513-20181010161625897-1984192577.png)

```
test_dict_df.drop(['id'],axis=1)
```

![img](https://img2018.cnblogs.com/blog/1023513/201810/1023513-20181010161640839-1236561806.png)

注意，drop()方法如果不设置参数inplace=True，则只能在生成的新数据块中实现删除效果，而不能删除原有数据块的相应行。因此

```
test_dict_df.drop(['id'],axis=1,inplace=True)
```

如果要删除连续多列，比如连续15列，采用

```
df.drop(df.columns[0:15],axis=1,inplace=True)
```

2. 删除行

删除某一行，在上面删除列操作的时候也稍有提及，如果不加axis=1，则默认按照**行号**进行删除，例如要删除第0行和第4行：

```
test_dict_df.drop([0,4])
```

![img](https://img2018.cnblogs.com/blog/1023513/201810/1023513-20181010161651824-879576679.png)

内容选自[博客园](https://www.cnblogs.com/datasnail/p/9767158.html)

### 2.14 fillna（）

此方法用于填充NaN的数据，将表格中的NaN数据填充自NaN数据左边的数据，但是不会改变原数据块的相应数据，因此要重新赋值。

```
file4['min'] = file4.fillna(axis=1,method='ffill').min2
```

内容选自[csdn](https://blog.csdn.net/weixin_39945523/article/details/112156653)



### 2.15 df[''].str.extract()

1. 先介绍str.extract()，可用正则从字符数据中抽取匹配的数据，只返回**第一个**匹配的数据。
2. 注意，正则表达式中必须有分组，只是返回分组中的数据，如果给分组取了名称，则该名称就是返回结果中的字段名。

![img](https://images2018.cnblogs.com/blog/1405422/201807/1405422-20180726230552116-956168501.png)

可采用的操作有

```
　　df["天数"]=df.路线信息.str.extract('(\d+)天\d+晚').apply(lambda x: int(x))
　　df["酒店评分"]=df.酒店信息.str.extract('(\d\.\d)分').apply(lambda x: float(x))
　　df["酒店等级"]=df.酒店信息.str.extract('\n(.*)')
　　df["价格"]=df.路线信息.str.extract('(\d+)起/人').apply(lambda x: int(x))
```

从路线信息中提取旅游天数、酒店等级、酒店评分、旅游价格等信息

内容参考自[博客园](https://www.cnblogs.com/dearL/p/9375058.html)和[csdn](https://blog.csdn.net/yj1556492839/article/details/79882488)



### 2.16 切片

1. 如果是df['列名']，返回一个Series对象
2. 如果是df[:n],返回一个对行切片的dataframe对象，前提是行号必须是数字。
3. 如果是df[布尔型索引]，此时可以直接赋值，能够更改原dataframe变量。



### 2.17 更改dataframe变量

- 如果要更改**原始数据**，请使用单一赋值操作（`loc`）：

```
data.loc[data.bidder == 'parakeet2004', 'bidderrate'] = 100
```

- 如果想通过

```
df[布尔表达式Series][列名] = 常数 或者 df[列名][布尔表达式Series] = 常数
```

这是不通过的，会提示

```
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
```

- 如果仅仅是df[布尔型索引]，此时可以直接赋值，能够更改原dataframe变量，但是可能会更改某一行的变量。

参考自[简书](https://www.jianshu.com/p/72274ccb647a)和[csdn](https://bbs.csdn.net/topics/392517369?list=687576)



### 2.18 .tolist()方法

1. 可以把Index对象转换成列表

```
df.columns.tolist()
```

2. 可以把array对象转换成列表

   ```
   np.array(temp['位号']).tolist()
   ```

   



## 3. 小技巧

### 3.1 设置自动断行

jupyter notebook中自动断行只需要回车就行了，一般系统还会自动对齐，python中可以使用 \ 当做续行符。



### 3.2  pd.set_option()

- pd.set_option(‘max_columns’,300)
- pd.set_option(‘max_row’,300) 
- pd.set_option('display.float_format',lambda x : '%.2f' % x)

指定做多现实的行数和列数。

ps:设置的行列数字必须要大于表格的行列数，否则的话仍然显示还是会省略掉想要的内容。

第三个是为了防止dataframe采用科学计数法显示，例如显示1e+2这种方法表示100就很麻烦。

